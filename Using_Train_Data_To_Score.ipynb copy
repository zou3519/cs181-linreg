{
 "metadata": {
  "name": "",
  "signature": "sha256:9b1345097ecb49e8761b870ad6ae61a42bdab7e1667751b787211622a87342f8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Only need to run 1st and 3rd cell once each. To run a test, just run 2nd and 4th cell(very fast). \n",
      "#Then go into the Excel document and compute =SQRT(0.00002*SUM(C2:C50001))\n",
      "\n",
      "#You also need to make a copy of the train file and make a csv file with an appropriate name (see below)\n",
      "\n",
      "import csv\n",
      "import gzip\n",
      "import numpy as np\n",
      "from sklearn import linear_model\n",
      "\n",
      "train_filename = 'train.csv.gz'\n",
      "test_filename  = 'train_copy.csv.gz'\n",
      "pred_filename  = 'Some_Predictions.csv'\n",
      "\n",
      "# Load the training file.\n",
      "train_data = []\n",
      "train_features = []\n",
      "with gzip.open(train_filename, 'r') as train_fh:\n",
      "\n",
      "    # Parse it as a CSV file.\n",
      "    train_csv = csv.reader(train_fh, delimiter=',', quotechar='\"')\n",
      "    \n",
      "    # Skip the header row.\n",
      "    next(train_csv, None)\n",
      "    \n",
      "    # Load the data, but only the first 50000 rows!\n",
      "    increment = 0\n",
      "    for row in train_csv:\n",
      "        if (increment < 200000):\n",
      "            smiles   = row[0]\n",
      "            features = np.array([float(x) for x in row[1:257]])\n",
      "            gap      = float(row[257])\n",
      "\n",
      "            train_data.append({ 'smiles':   smiles,\n",
      "                                'features': features,\n",
      "                                'gap':      gap })\n",
      "\n",
      "            train_features.append(features)\n",
      "            \n",
      "            increment = increment + 1\n",
      "\n",
      "    target = np.array([datum['gap'] for datum in train_data])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Insert whatever regression technique here.\n",
      "\n",
      "#clf = linear_model.ElasticNetCV(l1_ratio = [0.01, 0.02, 0.03, 0.04, .05], alphas=[1.175,100])\n",
      "#clf.fit(train_features, target)\n",
      "\n",
      "#print clf.alpha_, clf.l1_ratio_\n",
      "\n",
      "#from sklearn import ensemble\n",
      "\n",
      "clf = ensemble.RandomForestRegressor(n_estimators=100,max_features=\"sqrt\")\n",
      "clf.fit(train_features, target)\n",
      "\n",
      "#clf = linear_model.Ridge(0.5)\n",
      "#clf.fit(train_features, target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "RandomForestRegressor(bootstrap=True, compute_importances=None,\n",
        "           criterion='mse', max_depth=None, max_features='sqrt',\n",
        "           min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "           n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
        "           verbose=0)"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load the test file.\n",
      "test_filename  = 'train_copy.csv.gz'\n",
      "\n",
      "test_data = []\n",
      "test_features = []\n",
      "with gzip.open(test_filename, 'r') as test_fh:\n",
      "\n",
      "    # Parse it as a CSV file.\n",
      "    test_csv = csv.reader(test_fh, delimiter=',', quotechar='\"')\n",
      "    \n",
      "    # Skip the header row.\n",
      "    next(test_csv, None)\n",
      "\n",
      "    # Load the data.\n",
      "    theCount = 0\n",
      "    for row in test_csv:\n",
      "        if (theCount < 50000):\n",
      "            pass\n",
      "        elif (theCount >= 100000):\n",
      "            if (theCount < 150000):\n",
      "                smiles   = row[0]\n",
      "                features = np.array([float(x) for x in row[1:257]])\n",
      "                gap      = float(row[257])\n",
      "\n",
      "                test_data.append({ 'smiles':   smiles,\n",
      "                                'features': features,\n",
      "                                'gap':      gap })\n",
      "\n",
      "                test_features.append(features)\n",
      "        \n",
      "        theCount = theCount + 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Write a prediction file.\n",
      "\n",
      "the_predictions = np.array([])\n",
      "with open(pred_filename, 'w') as pred_fh:\n",
      "\n",
      "    # Produce a CSV file.\n",
      "    pred_csv = csv.writer(pred_fh, delimiter=',', quotechar='\"')\n",
      "\n",
      "    # Write the header row.\n",
      "    pred_csv.writerow(['Actual Value', 'Prediction', 'Squared Difference'])\n",
      "    \n",
      "    the_predictions = clf.predict(test_features)\n",
      "\n",
      "    counter = 0\n",
      "    for datum in test_data:\n",
      "        pred_csv.writerow([datum['gap'], the_predictions[counter], (datum['gap']-the_predictions[counter])**2])\n",
      "        counter = counter + 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#THE ACTUAL PREDICTION FILE. Chnage file name accordingly.\n",
      "\n",
      "test_filename  = 'test.csv.gz'\n",
      "\n",
      "# Load the test file.\n",
      "test_data = []\n",
      "test_features = []\n",
      "with gzip.open(test_filename, 'r') as test_fh:\n",
      "\n",
      "    # Parse it as a CSV file.\n",
      "    test_csv = csv.reader(test_fh, delimiter=',', quotechar='\"')\n",
      "    \n",
      "    # Skip the header row.\n",
      "    next(test_csv, None)\n",
      "\n",
      "    # Load the data.\n",
      "    for row in test_csv:\n",
      "        id       = row[0]\n",
      "        smiles   = row[1]\n",
      "        features = np.array([float(x) for x in row[2:258]])\n",
      "        \n",
      "        test_data.append({ 'id':       id,\n",
      "                           'smiles':   smiles,\n",
      "                           'features': features })\n",
      "        \n",
      "        test_features.append(features)\n",
      "\n",
      "# Write a prediction file.\n",
      "the_predictions = np.array([])\n",
      "with open(pred_filename, 'w') as pred_fh:\n",
      "\n",
      "    # Produce a CSV file.\n",
      "    pred_csv = csv.writer(pred_fh, delimiter=',', quotechar='\"')\n",
      "\n",
      "    # Write the header row.\n",
      "    pred_csv.writerow(['Id', 'Prediction'])\n",
      "    \n",
      "    the_predictions = clf.predict(test_features)\n",
      "\n",
      "    counter = 0\n",
      "    for datum in test_data:\n",
      "        pred_csv.writerow([datum['id'], the_predictions[counter]])\n",
      "        counter = counter + 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}