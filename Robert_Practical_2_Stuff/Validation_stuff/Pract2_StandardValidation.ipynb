{
 "metadata": {
  "name": "",
  "signature": "sha256:60c3bdffc5283cc796d43e6250cdd5345f33d546fa6e80410b9c01e7bb016bcf"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import linear_model\n",
      "from sklearn import ensemble\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 274
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 266
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "from collections import Counter\n",
      "try:\n",
      "    import xml.etree.cElementTree as ET\n",
      "except ImportError:\n",
      "    import xml.etree.ElementTree as ET\n",
      "import numpy as np\n",
      "from scipy import sparse\n",
      "\n",
      "import util\n",
      "\n",
      "\n",
      "def extract_feats(ffs, direc=\"train\", global_feat_dict=None):\n",
      "    \n",
      "    fds = [] # list of feature dicts\n",
      "    classes = []\n",
      "    ids = [] \n",
      "    counter = 0\n",
      "    for datafile in os.listdir(direc):\n",
      "        \n",
      "        #THis is fucked up and can't be switched to >248 for some reason. So it is validating on a subset of traning right now\n",
      "        #The Richard Features version is correct though\n",
      "        \n",
      "        if counter < 618: ###*******USE THIS TO CHANGE WHAT THE TRAINING DATA IS!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "                # extract id and true class (if available) from filename\n",
      "            id_str,clazz = datafile.split('.')[:2]\n",
      "            ids.append(id_str)\n",
      "            # add target class if this is training data\n",
      "            try:\n",
      "                classes.append(util.malware_classes.index(clazz)) #INDENT\n",
      "            except ValueError:\n",
      "                # we should only fail to find the label in our list of malware classes\n",
      "                # if this is test data, which always has an \"X\" label\n",
      "                assert clazz == \"X\"\n",
      "                #assert clazz = clazz\n",
      "                classes.append(-1)\n",
      "            rowfd = {}\n",
      "            # parse file as an xml document\n",
      "            tree = ET.parse(os.path.join(direc,datafile))\n",
      "            # accumulate features\n",
      "            [rowfd.update(ff(tree)) for ff in ffs]\n",
      "            fds.append(rowfd)\n",
      "\n",
      "            counter = counter + 1\n",
      "\n",
      "    X,feat_dict = make_design_mat(fds,global_feat_dict)\n",
      "    return X, feat_dict, np.array(classes), ids\n",
      "\n",
      "\n",
      "def make_design_mat(fds, global_feat_dict=None):\n",
      "    \n",
      "    if global_feat_dict is None:\n",
      "        all_feats = set()\n",
      "        [all_feats.update(fd.keys()) for fd in fds]\n",
      "        feat_dict = dict([(feat, i) for i, feat in enumerate(sorted(all_feats))])\n",
      "    else:\n",
      "        feat_dict = global_feat_dict\n",
      "        \n",
      "    cols = []\n",
      "    rows = []\n",
      "    data = []        \n",
      "    for i in xrange(len(fds)):\n",
      "        temp_cols = []\n",
      "        temp_data = []\n",
      "        for feat,val in fds[i].iteritems():\n",
      "            try:\n",
      "                # update temp_cols iff update temp_data\n",
      "                temp_cols.append(feat_dict[feat])\n",
      "                temp_data.append(val)\n",
      "            except KeyError as ex:\n",
      "                if global_feat_dict is not None:\n",
      "                    pass  # new feature in test data; nbd\n",
      "                else:\n",
      "                    raise ex\n",
      "\n",
      "        # all fd's features in the same row\n",
      "        k = len(temp_cols)\n",
      "        cols.extend(temp_cols)\n",
      "        data.extend(temp_data)\n",
      "        rows.extend([i]*k)\n",
      "\n",
      "    assert len(cols) == len(rows) and len(rows) == len(data)\n",
      "   \n",
      "\n",
      "    X = sparse.csr_matrix((np.array(data),\n",
      "                   (np.array(rows), np.array(cols))),\n",
      "                   shape=(len(fds), len(feat_dict)))\n",
      "    return X, feat_dict\n",
      "    \n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 281
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#binary on first and last system call in all_section\n",
      "def first_last_system_call_feats(tree):\n",
      "    c = Counter()\n",
      "    in_all_section = False\n",
      "    first = True # is this the first system call\n",
      "    last_call = None # keep track of last call we've seen\n",
      "    for el in tree.iter():\n",
      "        # ignore everything outside the \"all_section\" element\n",
      "        if el.tag == \"all_section\" and not in_all_section:\n",
      "            in_all_section = True\n",
      "        elif el.tag == \"all_section\" and in_all_section:\n",
      "            in_all_section = False\n",
      "        elif in_all_section:\n",
      "            if first:\n",
      "                c[\"first_call-\"+el.tag] = 1\n",
      "                first = False\n",
      "            last_call = el.tag  # update last call seen\n",
      "            \n",
      "    # finally, mark last call seen\n",
      "    c[\"last_call-\"+last_call] = 1\n",
      "    return c\n",
      "\n",
      "#number of total system calls in all_section\n",
      "def system_call_count_feats(tree):\n",
      "    c = Counter()\n",
      "    in_all_section = False\n",
      "    for el in tree.iter():\n",
      "        # ignore everything outside the \"all_section\" element\n",
      "        if el.tag == \"all_section\" and not in_all_section:\n",
      "            in_all_section = True\n",
      "        elif el.tag == \"all_section\" and in_all_section:\n",
      "            in_all_section = False\n",
      "        elif in_all_section:\n",
      "            c['num_system_calls'] += 1\n",
      "    return c\n",
      "\n",
      "#binary on whether each type of call is in all_section\n",
      "def indic_system_calls_by_type(tree):\n",
      "    c = Counter()\n",
      "    in_all_section = False\n",
      "    for el in tree.iter():\n",
      "        # ignore everything outside the \"all_section\" element\n",
      "        if el.tag == \"all_section\" and not in_all_section:\n",
      "            in_all_section = True\n",
      "        elif el.tag == \"all_section\" and in_all_section:\n",
      "            in_all_section = False\n",
      "        elif in_all_section:\n",
      "            c[\"a_call_type's_indic-\"+el.tag] = 1\n",
      "    return c\n",
      "\n",
      "#number of total system calls in entire file\n",
      "def system_call_count_all(tree):\n",
      "    c = Counter()\n",
      "    for el in tree.iter():\n",
      "        c['num_system_calls_all'] += 1\n",
      "    return c\n",
      "\n",
      "#count number of each system call in all_section\n",
      "def count_system_calls_by_type(tree):\n",
      "    c = Counter()\n",
      "    in_all_section = False\n",
      "    for el in tree.iter():\n",
      "        # ignore everything outside the \"all_section\" element\n",
      "        if el.tag == \"all_section\" and not in_all_section:\n",
      "            in_all_section = True\n",
      "        elif el.tag == \"all_section\" and in_all_section:\n",
      "            in_all_section = False\n",
      "        elif in_all_section:\n",
      "            c[\"a_call_type's_counter-\"+el.tag] += 1\n",
      "    return c\n",
      "\n",
      "#count max number of consecutive create_mutex calls\n",
      "def max_consec_create_mutex(tree):\n",
      "    c = Counter()\n",
      "    best = 0\n",
      "    current = 0\n",
      "    for el in tree.iter():\n",
      "        if el.tag == \"create_mutex\":\n",
      "            current = current + 1\n",
      "            if current > best:\n",
      "                best = current\n",
      "        else:\n",
      "            current = 0\n",
      "    c['create_mutex_max_block_num'] = best\n",
      "    return c\n",
      "\n",
      "#count number of blocks of 5 consecutive create_mutex calls\n",
      "def five_consec_create_mutex(tree):\n",
      "    c = Counter()\n",
      "    total = 0\n",
      "    current = 0\n",
      "    for el in tree.iter():\n",
      "        if el.tag == \"create_mutex\":\n",
      "            current = current + 1\n",
      "            if current == 5:\n",
      "                total = total + 1\n",
      "                current = 0\n",
      "        else:\n",
      "            current = 0\n",
      "    c['five_mutex_block_num'] = total\n",
      "    return c\n",
      "\n",
      "#binary based on whether one of Kevin's original 3 bad Swizzor sites is found under get_host_by_name\n",
      "def get_host_by_name_bad_ads_indic(tree):\n",
      "    c = Counter()\n",
      "    badadlist = ['ads.netbios-local.com', 'upd.host255-255-255-0.com', 'ads.range159-195.com']\n",
      "    badads = 0\n",
      "    for el in tree.iter():\n",
      "        if el.tag == \"get_host_by_name\":\n",
      "            for website in badadlist:\n",
      "                for key in el.attrib:\n",
      "                    if key == website:\n",
      "                        badads = 1\n",
      "    c['get_host_by_name_bad_ads'] = badads\n",
      "    return c\n",
      "\n",
      "#proportions of each type of system call\n",
      "def proportion_system_calls_by_type(tree):\n",
      "    c = Counter()\n",
      "    d = {}\n",
      "    totalcalls = 0.0\n",
      "    for el in tree.iter():\n",
      "        totalcalls = totalcalls + 1\n",
      "        c[\"a_call_type's_prop_overall-\"+el.tag] += 1\n",
      "    for key in c:\n",
      "        d[key] = c[key] / totalcalls\n",
      "    return d\n",
      "\n",
      "#see how closely correspond to VB 28kb specific counts in all_section\n",
      "def counts_compared_to_small_VB(tree):\n",
      "    c = Counter()\n",
      "    in_all_section = False\n",
      "    for el in tree.iter():\n",
      "        # ignore everything outside the \"all_section\" element\n",
      "        if el.tag == \"all_section\" and not in_all_section:\n",
      "            in_all_section = True\n",
      "        elif el.tag == \"all_section\" and in_all_section:\n",
      "            in_all_section = False\n",
      "        elif in_all_section:\n",
      "            c[el.tag] += 1\n",
      "    closeness = 0\n",
      "    VBdict = {'load_image':1,'load_dll':26, 'check_for_debugger':1, 'get_system_directory':8,\n",
      "              'open_key':14,'query_value':7,'create_mutex':6, 'set_windows_hook':3,\n",
      "              'create_window':4,'show_window':1,'get_username':1,'find_file':5,\n",
      "              'read_value':2,'get_file_attributes':2,'get_windows_directory':1,\n",
      "              'destroy_window':3,'enum_window':4,'sleep':1,'kill_process':1}\n",
      "    for atag in VBdict:\n",
      "        for key in c:\n",
      "            if atag==key:\n",
      "                if c[key] == VBdict[atag]:\n",
      "                    closeness += 1\n",
      "    d = {\"VB_small_closeness\":closeness}\n",
      "    return d"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 282
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## The following function does the feature extraction, learning, and prediction\n",
      "def main():\n",
      "    train_dir = \"train\" ####NOTE FILE NAME!!!!!!!!!\n",
      "    test_dir = \"validation\" ####NOTE FILE NAME!!!!!!!!!!!!!!!\n",
      "    outputfile = \"mytrialpredictions.csv\"  # NOTE FILE NAME!!! feel free to change this or take it as an argument\n",
      "    \n",
      "    # TODO put the names of the feature functions you've defined above in this list\n",
      "    ffs = [first_last_system_call_feats,\n",
      "           system_call_count_feats,\n",
      "           indic_system_calls_by_type,\n",
      "           system_call_count_all,\n",
      "           count_system_calls_by_type,\n",
      "           max_consec_create_mutex,\n",
      "           five_consec_create_mutex,\n",
      "           get_host_by_name_bad_ads_indic,\n",
      "           proportion_system_calls_by_type,\n",
      "           counts_compared_to_small_VB]\n",
      "    #ffs = [first_last_system_call_feats]\n",
      "    #ffs = [system_call_count_feats]\n",
      "    #ffs = [indic_system_calls_by_type]\n",
      "    \n",
      "    # extract features\n",
      "    print \"extracting training features...\"\n",
      "    X_train,global_feat_dict,t_train,train_ids = extract_feats(ffs, train_dir)\n",
      "    print \"done extracting training features\"\n",
      "    print\n",
      "    \n",
      "    print X_train.shape\n",
      "    #print X_train\n",
      "    \n",
      "\n",
      "    print \"learning...\"\n",
      "\n",
      "    \n",
      "    clf = ensemble.RandomForestClassifier(n_estimators=5, max_features=\"sqrt\") #Choose number of trees, etc. here\n",
      "    clf.fit(X_train.toarray(),t_train) #\n",
      "    \n",
      "    \n",
      "    print \"done learning\"\n",
      "    print\n",
      "    \n",
      "    # get rid of training data and load test data\n",
      "    del X_train\n",
      "    del t_train\n",
      "    del train_ids\n",
      "    print \"extracting test features...\"\n",
      "    X_test,_,t_ignore,test_ids = extract_feats(ffs, test_dir, global_feat_dict=global_feat_dict)\n",
      "    #X_test,_,t_ignore,test_ids = extract_feats(ffs, test_dir)\n",
      "    #print t_ignore\n",
      "    \n",
      "    print \"done extracting test features\"\n",
      "    print\n",
      "    \n",
      "\n",
      "    print \"making predictions...\"\n",
      "\n",
      "    preds = clf.predict(X_test.toarray())\n",
      "    \n",
      "    print \"done making predictions\"\n",
      "    print\n",
      "\n",
      "    \n",
      "    #print clf.feature_importances_\n",
      "\n",
      "    \n",
      "    print \"writing predictions...\"\n",
      "    util.write_predictions(preds, test_ids, outputfile)\n",
      "    \n",
      "    print \"done!\"\n",
      "    \n",
      "    #IMPORTANT\n",
      "    #STUFF FOR VALIDATION SCORING: You need to go to the Excel document validationdata.csv. All the predictions are\n",
      "    #listed in a column, and the actual classes are right below it. Use the Excel if and sum functions to calculate score...\n",
      "    \n",
      "    #Ex. IF(A1=A619,1,0) dragged through cells B1 to B618, then SUM(B1:B618) to get number of correct predictions\n",
      "        \n",
      "    newstack = np.hstack((preds.astype(int),t_ignore))\n",
      "    #print newstack\n",
      "    np.savetxt(\"validationdata.csv\", newstack, delimiter=\" \")\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "extracting training features...\n",
        "done extracting training features"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "(617, 295)\n",
        "learning...\n",
        "done learning\n",
        "\n",
        "extracting test features...\n",
        "done extracting test features"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "making predictions...\n",
        "done making predictions\n",
        "\n",
        "writing predictions...\n",
        "done!\n"
       ]
      }
     ],
     "prompt_number": 283
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}